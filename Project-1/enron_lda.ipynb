{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "# for plotting\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "# prep NLTK Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10348, 2)\n",
      "                              file  \\\n",
      "186822  jones-t/all_documents/634.   \n",
      "308790  mann-k/all_documents/5690.   \n",
      "82383         dasovich-j/sent/423.   \n",
      "227299          kaminski-v/var/63.   \n",
      "301824     mann-k/_sent_mail/3208.   \n",
      "\n",
      "                                                  message  \n",
      "186822  Message-ID: <17820178.1075846925335.JavaMail.e...  \n",
      "308790  Message-ID: <29110382.1075845717882.JavaMail.e...  \n",
      "82383   Message-ID: <6812040.1075843194135.JavaMail.ev...  \n",
      "227299  Message-ID: <21547648.1075856642126.JavaMail.e...  \n",
      "301824  Message-ID: <12684200.1075846107179.JavaMail.e...  \n"
     ]
    }
   ],
   "source": [
    "# Read the emails\n",
    "emails = pd.read_csv(\"emails.csv\")\n",
    "email_subset = emails.sample(frac=0.02,random_state=1)\n",
    "print(email_subset.shape)\n",
    "print(email_subset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing data out from the raw messages\n",
    "\n",
    "def parse_raw_message(raw_message):\n",
    "    lines = raw_message.split('\\n')\n",
    "    email = {}\n",
    "    message = ''\n",
    "    keys_to_extract = ['message-id', 'from', 'to']\n",
    "    for line in lines:\n",
    "        if ':' not in line:\n",
    "            message += line.strip()\n",
    "            email['body'] = message\n",
    "        else:\n",
    "            pairs = line.split(':')\n",
    "            key = pairs[0].lower()\n",
    "            val = pairs[1].strip()\n",
    "            if key in keys_to_extract:\n",
    "                email[key] = val\n",
    "    return email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_list(emails, key):\n",
    "    results = []\n",
    "    for email in emails:\n",
    "        if key not in email:\n",
    "            results.append('')\n",
    "        else:\n",
    "            results.append(email[key])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_into_emails(messages):\n",
    "    emails = [parse_raw_message(message) for message in messages]\n",
    "    return {\n",
    "        'body': map_to_list(emails, 'body'),\n",
    "        'to': map_to_list(emails, 'to'),\n",
    "        'from_': map_to_list(emails, 'from'),\n",
    "        'msg_id': map_to_list(emails, 'message-id')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                body  \\\n",
      "0  It would be nice if you could be at my dinner,...   \n",
      "1  Absolutely.Good point!  Can Peter start to dra...   \n",
      "2  My apologies.  My schedule melted down after w...   \n",
      "3  Vince,UK VAR breached the limit last week.UK t...   \n",
      "4  Any problems/comments?AM ---------------------...   \n",
      "\n",
      "                                                  to  \\\n",
      "0                           alicia.goodrow@enron.com   \n",
      "1                          Kay Mann/Corp/Enron@ENRON   \n",
      "2                        christine.piesco@oracle.com   \n",
      "3  Richard Lewis/LON/ECT@ECT, James New/LON/ECT@E...   \n",
      "4  Don Hammond/PDX/ECT@ECT, Jody Blackburn/PDX/EC...   \n",
      "\n",
      "                               from_  \\\n",
      "0               tana.jones@enron.com   \n",
      "1  Sheila Tweed@ECT on 05/15/2001 06   \n",
      "2            jeff.dasovich@enron.com   \n",
      "3        tanya.tamarchenko@enron.com   \n",
      "4                 kay.mann@enron.com   \n",
      "\n",
      "                                          msg_id  \n",
      "0  <17820178.1075846925335.JavaMail.evans@thyme>  \n",
      "1  <29110382.1075845717882.JavaMail.evans@thyme>  \n",
      "2   <6812040.1075843194135.JavaMail.evans@thyme>  \n",
      "3  <21547648.1075856642126.JavaMail.evans@thyme>  \n",
      "4  <12684200.1075846107179.JavaMail.evans@thyme>  \n"
     ]
    }
   ],
   "source": [
    "email_df = pd.DataFrame(parse_into_emails(email_subset.message))\n",
    "print(email_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My apologies.  My schedule melted down after we talked on Monday.  Here'swhere folks came out.  There's some concern about size.  We're supposed to beno larger than 3, but we lobbied Aceves and he apparently Ok'd our\"oversized\" group.  The other folks in the group--who talked to himoriginally--are pretty sure that five will violate the rules.  Folks wonderedif there were other groups that are smaller than ours that you could hook upwith.  Sorry about that---it's a wrinkle that I didn't think about when wespoke.  If it gets real ugly trying to find a smaller group, let me know.Fortunately there's not another team case due for two weeks.Best,Jeff\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "print(email_df.iloc[2]['body'])\n",
    "# Convert email body to list\n",
    "data = email_df.body.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize - break down each sentence into a list of words\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vince', 'uk', 'var', 'breached', 'the', 'limit', 'last', 'week', 'uk', 'traders', 'asked', 'us', 'to', 'review', 'the', 'correlations', 'across', 'uk', 'gas', 'and', 'power', 'aswell', 'as', 'the', 'correlations', 'across', 'efa', 'slots', 'we', 'did', 'part', 'of', 'the', 'work', 'last', 'week', 'now', 'we', 'll', 'update', 'the', 'correlations', 'based', 'on', 'historical', 'prices', 'tanya', 'richard', 'lewisleppard', 'lon', 'ect', 'ect', 'rudy', 'dautel', 'hou', 'ect', 'ect', 'kirstee', 'hewitt', 'lon', 'ect', 'ect', 'naveen', 'andrews', 'corp', 'enron', 'enron', 'david', 'port', 'market', 'risk', 'corp', 'enron', 'enron', 'tedmurphy', 'hou', 'ect', 'ect', 'simon', 'hastings', 'lon', 'ect', 'ect', 'paul', 'arcy', 'lon', 'ect', 'ect', 'amirghodsian', 'lon', 'ect', 'ectthanks', 'tanya', 'these', 'are', 'interesting', 'results', 'am', 'on', 'vacation', 'next', 'week', 'sohere', 'are', 'my', 'current', 'thoughts', 'am', 'contactable', 'on', 'my', 'mobile', 'if', 'necessary', 'gas', 'to', 'power', 'correlationsi', 'see', 'your', 'point', 'about', 'gas', 'to', 'power', 'correlation', 'only', 'affecting', 'var', 'for', 'theconservative', 'long', 'term', 'correlation', 'combined', 'var', 'is', 'mm', 'less', 'thanpreviously', 'expected', 'so', 'how', 'does', 'this', 'affect', 'the', 'limit', 'breach', 'we', 'are', 'still', 'over', 'our', 'uk', 'power', 'limit', 'but', 'the', 'limit', 'was', 'set', 'when', 'wewere', 'assuming', 'no', 'gas', 'power', 'correlation', 'and', 'therefore', 'higher', 'portfolio', 'var', 'suggested', 'way', 'forward', 'given', 'the', 'importance', 'of', 'the', 'spread', 'options', 'to', 'the', 'ukgas', 'and', 'power', 'books', 'can', 'we', 'allocate', 'to', 'the', 'gas', 'and', 'power', 'books', 'share', 'of', 'the', 'reduction', 'inportfolio', 'var', 'ie', 'reduction', 'portfolio', 'var', 'sum', 'power', 'var', 'gas', 'var', 'also', 'if', 'understand', 'your', 'mail', 'correctly', 'matrix', 'implies', 'gas', 'is', 'consistent', 'with', 'our', 'correlation', 'curves', 'and', 'this', 'reduces', 'totalvar', 'by', 'mm', 'efa', 'slot', 'correlationsthe', 'issue', 'of', 'whether', 'our', 'existing', 'efa', 'to', 'efa', 'correlation', 'matrix', 'is', 'correct', 'isa', 'separate', 'issue', 'don', 'understand', 'where', 'the', 'matrix', 'efa', 'to', 'efacorrelations', 'come', 'from', 'but', 'am', 'happy', 'for', 'you', 'to', 'run', 'some', 'from', 'the', 'forward', 'curves', 'use', 'the', 'first', 'years', 'wouldsuggest', 'our', 'original', 'matrix', 'was', 'based', 'on', 'historicals', 'but', 'the', 'analysis', 'isworth', 'doing', 'again', 'your', 'matrix', 'results', 'certainly', 'indicate', 'how', 'importantthese', 'correlations', 'are', 'closing', 'thoughtsfriday', 'trading', 'left', 'us', 'longer', 'so', 'would', 'not', 'expect', 'limit', 'breach', 'onmonday', 'we', 'are', 'still', 'reviewing', 'the', 'shape', 'of', 'the', 'long', 'term', 'curve', 'and', 'dlike', 'to', 'wait', 'until', 'both', 'simon', 'hastings', 'and', 'are', 'back', 'in', 'the', 'office', 'mondayweek', 'before', 'finalising', 'this', 'tamarchenkonew', 'lon', 'ect', 'ect', 'steven', 'leppard', 'lon', 'ect', 'ect', 'rudy', 'dautel', 'hou', 'ect', 'ect', 'kirsteehewitt', 'lon', 'ect', 'ect', 'naveen', 'andrews', 'corp', 'enron', 'enron', 'david', 'port', 'marketrisk', 'corp', 'enron', 'enron', 'ted', 'murphy', 'hou', 'ect', 'ecteverybody', 'oliver', 'sent', 'us', 'the', 'var', 'number', 'for', 'different', 'correlations', 'for', 'uk', 'powerportfolio', 'separately', 'from', 'uk', 'gas', 'portfolio', 'first', 'if', 'var', 'is', 'calculated', 'accurately', 'the', 'correlation', 'between', 'power', 'and', 'gascurves', 'should', 'not', 'affect', 'var', 'number', 'for', 'power', 'and', 'var', 'number', 'for', 'gas', 'onlythe', 'aggregate', 'number', 'will', 'be', 'affected', 'the', 'changes', 'you', 'see', 'are', 'due', 'to', 'thefact', 'that', 'we', 'use', 'monte', 'carlo', 'simulation', 'method', 'which', 'accuracy', 'depends', 'on', 'the', 'number', 'of', 'simulations', 'even', 'if', 'we', 'don', 'changethe', 'correlations', 'but', 'use', 'different', 'realizations', 'of', 'random', 'numbers', 'we', 'get', 'slightly', 'different', 'result', 'from', 'the', 'model', 'we', 'should', 'look', 'at', 'the', 'aggregate', 'number', 'calculated', 'weighted', 'correlations', 'based', 'on', 'curves', 'got', 'from', 'paul', 'as', 'theweights', 'along', 'the', 'term', 'structure', 'used', 'the', 'product', 'of', 'price', 'position', 'andvolatility', 'for', 'each', 'time', 'bucket', 'for', 'gas', 'and', 'each', 'of', 'efa', 'slots', 'the', 'these', 'numbers', 'into', 'the', 'original', 'correlation', 'matrix', 'definite', 'correlation', 'matrix', 'which', 'brakes', 'var', 'engine', 'correlation', 'matrix', 'for', 'any', 'set', 'of', 'random', 'variables', 'is', 'non', 'negative', 'bydefinition', 'and', 'remains', 'non', 'negatively', 'definite', 'if', 'calculated', 'properly', 'basedon', 'any', 'historical', 'data', 'here', 'according', 'to', 'our', 'phone', 'discussion', 'we', 'started', 'experimenting', 'assuming', 'the', 'same', 'correlation', 'for', 'each', 'efa', 'slot', 'and', 'et', 'elecversus', 'gas', 'am', 'sending', 'you', 'the', 'spreadsheet', 'which', 'summaries', 'the', 'results', 'inaddition', 'to', 'the', 'aggregate', 'var', 'numbers', 'for', 'the', 'runs', 'oliver', 'did', 'you', 'can', 'seethe', 'var', 'numbers', 'based', 'on', 'correlation', 'matrix', 'and', 'matrix', 'in', 'matrix', 'thecorrelations', 'across', 'efa', 'slots', 'are', 'identical', 'to', 'these', 'in', 'original', 'matrix', 'obtained', 'this', 'matrix', 'by', 'trial', 'and', 'error', 'matrix', 'is', 'produces', 'by', 'naveenusing', 'finger', 'algorithm', 'it', 'differs', 'from', 'original', 'matrix', 'across', 'efa', 'slots', 'aswellas', 'in', 'power', 'versus', 'gas', 'correlations', 'and', 'gives', 'higher', 'var', 'than', 'matrix', 'does', 'calculate', 'historical', 'correlations', 'from', 'them', 'tanya', 'oliver', 'gaylardleppard', 'lon', 'ect', 'ect', 'rudy', 'dautel', 'hou', 'ect', 'ect', 'kirstee', 'hewitt', 'lon', 'ect', 'ect', 'naveen', 'andrews', 'corp', 'enron', 'enron', 'tanya', 'tamarchenko', 'hou', 'ect', 'ect', 'davidport', 'market', 'risk', 'corp', 'enron', 'var', 'uk', 'power', 'book', 'var', 'uk', 'gas', 'book', 'mm', 'mm', 'mm', 'mm', 'mm', 'mm', 'mm', 'mm', 'cholesky', 'decomposition', 'failed', 'not', 'positive', 'definite', 'cholesky', 'decomposition', 'failed', 'not', 'positive', 'definite', 'cholesky', 'decomposition', 'failed', 'not', 'positive', 'definite', 'cholesky', 'decomposition', 'failed', 'not', 'positive', 'definite', 'cholesky', 'decomposition', 'failed', 'not', 'positive', 'definite', 'cholesky', 'decomposition', 'failed', 'not', 'positive', 'definite', 'cholesky', 'decomposition', 'failed', 'not', 'positive', 'definite', 'peaks', 'and', 'off', 'peaks', 'were', 'treated', 'the', 'same', 'to', 'avoid', 'violating', 'the', 'matrix', 'sintegrity', 'interesting', 'to', 'note', 'that', 'for', 'higher', 'correlation', 'of', 'the', 'power', 'varincreases', 'which', 'is', 'counter', 'to', 'intuition', 'this', 'implies', 'that', 'we', 'need', 'to', 'lookinto', 'how', 'the', 'correlations', 'are', 'being', 'applied', 'within', 'the', 'model', 'once', 'we', 'canderive', 'single', 'correlations', 'from', 'the', 'term', 'structure', 'is', 'the', 'next', 'action', 'tounderstand', 'how', 'they', 'are', 'being', 'applied', 'and', 'whether', 'the', 'model', 'captures', 'the', 'lvolatility', 'in', 'the', 'spread', 'option', 'deals', 'from', 'onwards', 'the', 'var', 'calculation', 'failed', 'oliver']\n"
     ]
    }
   ],
   "source": [
    "print(data_words[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "# higher threshold fewer phrases.\n",
    "bigram = Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram = Phrases(bigram[data_words], threshold=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_image_image', 'getting', 'together', 'for', 'the', 'holidays', 'is', 'something', 'we', 'all', 'enjoy', 'whether', 'it', 'gathering', 'with', 'old', 'friends', 'from', 'out', 'of', 'town', 'or', 'hanging', 'out', 'with', 'the', 'usual', 'gang', 'every', 'gathering', 'this', 'time', 'of', 'year', 'seems', 'little', 'more', 'special', 'we', 'at', 'miller_brewing', 'wish', 'you', 'many', 'happy', 'celebrations', 'this', 'season', 'and', 'thank', 'you', 'for', 'enjoying', 'those', 'occasions', 'responsibly', 'happy_holidays', 'image', 'this', 'mail', 'is', 'not', 'sent', 'unsolicited', 'you', 'subscribed', 'to', 'receive', 'information', 'from', 'miller_brewing', 'at', 'miller', 'web_site', 'or', 'event', 'must', 'be', 'or', 'older', 'to', 'visit', 'our', 'web_site', 'miller_brewing', 'co', 'milwaukee', 'wi', 'miller_brewing', 'company', 'milwaukee', 'wi', 'privacy_statement', 'image_image_image_image', 'this', 'message', 'was', 'sent', 'by', 'miller_brewing', 'company', 'using', 'responsys', 'interact', 'tm', 'click_here', 'if', 'you', 'prefer', 'not', 'to', 'receive', 'future', 'mail', 'from', 'miller_brewing', 'company', 'click_here', 'to', 'view', 'our', 'permission', 'marketing', 'policy', 'image']\n"
     ]
    }
   ],
   "source": [
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = Phraser(bigram)\n",
    "trigram_mod = Phraser(trigram)\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[200]]])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2398cd6c937708e42b80c0dce25ca405d0c6827c5ebcbcac9817d73cd0bc02f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 ('dsc650')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
